{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "453f8450",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5eef1319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import strftime\n",
    "from numpy.random import seed\n",
    "seed(888)\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1 import set_random_seed\n",
    "set_random_seed(404)\n",
    "\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91944520",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4e9021e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN_PATH = './MNIST/digit_xtrain.csv'\n",
    "X_TEST_PATH = './MNIST/digit_xtest.csv'\n",
    "Y_TRAIN_PATH = './MNIST/digit_ytrain.csv'\n",
    "Y_TEST_PATH = './MNIST/digit_ytest.csv'\n",
    "\n",
    "LOGGING_PATH = 'tensorboard_mnist_digit_log'\n",
    "\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "CHANNELS = 1\n",
    "TOTAL_INPUT = IMAGE_HEIGHT * IMAGE_WIDTH * CHANNELS\n",
    "\n",
    "NUMBER_OF_CLASSES = 10\n",
    "VALIDATION_SIZE = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a792a0e",
   "metadata": {},
   "source": [
    "## Getting the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8dae9ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 125 ms\n",
      "Wall time: 135 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_train_all = np.loadtxt(Y_TRAIN_PATH, delimiter=',', dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "7583a40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8b79a15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.loadtxt(Y_TEST_PATH, delimiter=',', dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1d32a299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 16.6 s\n",
      "Wall time: 16.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "x_train_all = np.loadtxt(X_TRAIN_PATH, delimiter=',', dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3e922ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.8 s\n",
      "Wall time: 2.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "x_test = np.loadtxt(X_TEST_PATH, delimiter=',', dtype = int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2661b472",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "52f2baf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9e023f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
       "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
       "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
       "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
       "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
       "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
       "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
       "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
       "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
       "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0 means that the pixel is completely white whereas the value 255 indicates that the pixel is extremely dark\n",
    "x_train_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ce970fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8edc2454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb18b586",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8c9df3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-scaling\n",
    "x_train_all, x_test = x_train_all/255.0, x_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd31dcb3",
   "metadata": {},
   "source": [
    "### Convert target values to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9610e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all = np.eye(NUMBER_OF_CLASSES)[y_train_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6a84cdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "05eabcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.eye(NUMBER_OF_CLASSES)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "cf5c4816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781624c1",
   "metadata": {},
   "source": [
    "## Create validation dataset from training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "6a90a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation = x_train_all[:VALIDATION_SIZE]\n",
    "y_validation = y_train_all[:VALIDATION_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "494062de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_all[VALIDATION_SIZE:]\n",
    "y_train = y_train_all[VALIDATION_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "dfc72002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1b5dc516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f5934",
   "metadata": {},
   "source": [
    "## Setting up TensorFlow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "cb23e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "X = tf.placeholder(tf.float32, shape = [None, TOTAL_INPUT], name='X')\n",
    "Y = tf.placeholder(tf.float32, shape = [None, NUMBER_OF_CLASSES], name='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4411efb9",
   "metadata": {},
   "source": [
    "### Setting up Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e61c7c",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "f27b9f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "\n",
    "hidden_layer_1 = 512\n",
    "hidden_layer_2 = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "524272cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_layer(input, weight_dim, bias_dim , name):\n",
    "    with tf.name_scope(name):\n",
    "        initial_weight = tf.truncated_normal(shape = weight_dim, stddev=0.1, seed=42)\n",
    "        weight = tf.Variable(initial_value = initial_weight, name='W')\n",
    "\n",
    "        initial_bias = tf.constant(value = 0.0, shape = bias_dim)\n",
    "        bias = tf.Variable(initial_value = initial_bias, name='B')\n",
    "\n",
    "        layer_in = tf.matmul(input, weight) + bias\n",
    "        \n",
    "        if name=='out':\n",
    "            layer_out = tf.nn.softmax(layer_in)\n",
    "        else:\n",
    "            layer_out = tf.nn.relu(layer_in)\n",
    "            \n",
    "        tf.summary.histogram('weights', weight)\n",
    "        tf.summary.histogram('biases', bias)\n",
    "        \n",
    "        return layer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "f74dade3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mithun\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "layer_1 = setup_layer(X, weight_dim=[TOTAL_INPUT, hidden_layer_1], \n",
    "                      bias_dim=[hidden_layer_1], name='layer_1')\n",
    "\n",
    "layer_drop = tf.nn.dropout(layer_1, keep_prob=0.85, name='dropout_layer')\n",
    "\n",
    "layer_2 = setup_layer(layer_drop, weight_dim=[hidden_layer_1, hidden_layer_2], \n",
    "                      bias_dim=[hidden_layer_2], name='layer_2')\n",
    "output = setup_layer(layer_2, weight_dim=[hidden_layer_2, NUMBER_OF_CLASSES], \n",
    "                      bias_dim=[NUMBER_OF_CLASSES], name='out')\n",
    "\n",
    "model_name = f'{hidden_layer_1}-Dropout-{hidden_layer_2} LR{learning_rate} E{number_of_epochs}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "625f9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.name_scope('Hidden_layer_1'):\n",
    "#     #Creating the first layer\n",
    "#     initial_weight_1 = tf.truncated_normal(shape = [TOTAL_INPUT, hidden_layer_1], stddev=0.1, seed=42)\n",
    "#     weight_1 = tf.Variable(initial_value = initial_weight_1, name='W1')\n",
    "\n",
    "#     initial_bias_1 = tf.constant(value = 0.0, shape = [hidden_layer_1])\n",
    "#     bias_1 = tf.Variable(initial_value = initial_bias_1, name='B1')\n",
    "\n",
    "#     layer_1_input = tf.matmul(X, weight_1) + bias_1\n",
    "#     layer_1_output = tf.nn.relu(layer_1_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "dff072a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.name_scope('Hidden_layer_2'):\n",
    "#     # Creating the second layer\n",
    "#     initial_weight_2 = tf.truncated_normal(shape = [hidden_layer_1, hidden_layer_2], stddev=0.1, seed=42)\n",
    "#     weight_2 = tf.Variable(initial_value = initial_weight_2, name='W2')\n",
    "\n",
    "#     initial_bias_2 = tf.constant(value = 0.0, shape = [hidden_layer_2])\n",
    "#     bias_2 = tf.Variable(initial_value = initial_bias_2, name='B2')\n",
    "\n",
    "#     layer_2_input = tf.matmul(layer_1_output, weight_2) + bias_2\n",
    "#     layer_2_output = tf.nn.relu( layer_2_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "33a65c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.name_scope('output_layer'):\n",
    "#     # Creating the OUTPUT layer\n",
    "#     initial_weight_3 = tf.truncated_normal(shape =[hidden_layer_2,NUMBER_OF_CLASSES], stddev=0.1, seed=42)\n",
    "#     weight_3 = tf.Variable(initial_value = initial_weight_3, name='W3')\n",
    "\n",
    "#     initial_bias_3 = tf.constant(value = 0.0, shape = [NUMBER_OF_CLASSES])\n",
    "#     bias_3 = tf.Variable(initial_value = initial_bias_3, name='B3')\n",
    "\n",
    "#     layer_3_input = tf.matmul(layer_2_output, weight_3) + bias_3\n",
    "#     output = tf.nn.softmax( layer_3_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a71975",
   "metadata": {},
   "source": [
    "## Tensorboard Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "181e2bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard_mnist_digit_log\\512-Dropout-64 LR0.001 E50 at 23-30\n",
      "Sucessfully created directory\n"
     ]
    }
   ],
   "source": [
    "#Folders for tensorboard\n",
    "folder_name = f'{model_name} at {strftime(\"%H-%M\")}'\n",
    "directory = os.path.join(LOGGING_PATH, folder_name)\n",
    "print(directory)\n",
    "try:\n",
    "    os.makedirs(directory) \n",
    "except OSError as exception:\n",
    "    print(exception.strerror)\n",
    "else:\n",
    "    print('Sucessfully created directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de832979",
   "metadata": {},
   "source": [
    "## Loss, Optimisation and Metrics\n",
    "### Defining Loss Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "58ff7b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss_calc'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels =Y , logits=output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc0375b",
   "metadata": {},
   "source": [
    "### Defining Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "cfddc193",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d993fd55",
   "metadata": {},
   "source": [
    "### Accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "fb9e10a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(output, axis=1) , tf.argmax(Y, axis=1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "faa47ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('performance'):\n",
    "    tf.summary.scalar('cost', loss)\n",
    "    tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b372b7",
   "metadata": {},
   "source": [
    "## Check input images in TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "7fec678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('show_image'):\n",
    "    x_image = tf.reshape(X, [-1, 28, 28 ,1])\n",
    "    tf.summary.image('image_input', x_image, max_outputs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8309860a",
   "metadata": {},
   "source": [
    "## Run Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "2f577b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f865e6",
   "metadata": {},
   "source": [
    "## Setup FileWriter and Merge Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "2739b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_summary = tf.summary.merge_all()\n",
    "d_r = directory + '/train'\n",
    "train_writer = tf.summary.FileWriter(d_r)\n",
    "train_writer.add_graph(session.graph)\n",
    "\n",
    "validation_writer = tf.summary.FileWriter(directory + '/validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f82d80",
   "metadata": {},
   "source": [
    "## Initialize all varibales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "66bfce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the variables \n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aa5db4",
   "metadata": {},
   "source": [
    "## Making Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "0d5fcf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_batch = 1000\n",
    "num_examples = y_train.shape[0]\n",
    "number_iterations = int(num_examples/ size_of_batch)\n",
    "\n",
    "index_in_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "dd3c832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(batch_size, dataset, labels):\n",
    "    \n",
    "    global num_examples\n",
    "    global index_in_epoch\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    if index_in_epoch > num_examples:\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "    \n",
    "    end = index_in_epoch\n",
    "    \n",
    "    return dataset[start: end], labels[start: end]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60b35dc",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "0623f83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \t | Training Accuracy = 0.8479999899864197\n",
      "Epoch 1 \t | Training Accuracy = 0.8650000095367432\n",
      "Epoch 2 \t | Training Accuracy = 0.8659999966621399\n",
      "Epoch 3 \t | Training Accuracy = 0.8730000257492065\n",
      "Epoch 4 \t | Training Accuracy = 0.8730000257492065\n",
      "Epoch 5 \t | Training Accuracy = 0.9769999980926514\n",
      "Epoch 6 \t | Training Accuracy = 0.9779999852180481\n",
      "Epoch 7 \t | Training Accuracy = 0.9810000061988831\n",
      "Epoch 8 \t | Training Accuracy = 0.9789999723434448\n",
      "Epoch 9 \t | Training Accuracy = 0.9850000143051147\n",
      "Epoch 10 \t | Training Accuracy = 0.984000027179718\n",
      "Epoch 11 \t | Training Accuracy = 0.9869999885559082\n",
      "Epoch 12 \t | Training Accuracy = 0.9829999804496765\n",
      "Epoch 13 \t | Training Accuracy = 0.9860000014305115\n",
      "Epoch 14 \t | Training Accuracy = 0.9900000095367432\n",
      "Epoch 15 \t | Training Accuracy = 0.9879999756813049\n",
      "Epoch 16 \t | Training Accuracy = 0.9909999966621399\n",
      "Epoch 17 \t | Training Accuracy = 0.9879999756813049\n",
      "Epoch 18 \t | Training Accuracy = 0.9900000095367432\n",
      "Epoch 19 \t | Training Accuracy = 0.9919999837875366\n",
      "Epoch 20 \t | Training Accuracy = 0.9900000095367432\n",
      "Epoch 21 \t | Training Accuracy = 0.9919999837875366\n",
      "Epoch 22 \t | Training Accuracy = 0.9929999709129333\n",
      "Epoch 23 \t | Training Accuracy = 0.9909999966621399\n",
      "Epoch 24 \t | Training Accuracy = 0.9919999837875366\n",
      "Epoch 25 \t | Training Accuracy = 0.9940000176429749\n",
      "Epoch 26 \t | Training Accuracy = 0.9919999837875366\n",
      "Epoch 27 \t | Training Accuracy = 0.9929999709129333\n",
      "Epoch 28 \t | Training Accuracy = 0.9929999709129333\n",
      "Epoch 29 \t | Training Accuracy = 0.9919999837875366\n",
      "Epoch 30 \t | Training Accuracy = 0.9940000176429749\n",
      "Epoch 31 \t | Training Accuracy = 0.9940000176429749\n",
      "Epoch 32 \t | Training Accuracy = 0.9929999709129333\n",
      "Epoch 33 \t | Training Accuracy = 0.9929999709129333\n",
      "Epoch 34 \t | Training Accuracy = 0.9929999709129333\n",
      "Epoch 35 \t | Training Accuracy = 0.9940000176429749\n",
      "Epoch 36 \t | Training Accuracy = 0.9940000176429749\n",
      "Epoch 37 \t | Training Accuracy = 0.9940000176429749\n",
      "Epoch 38 \t | Training Accuracy = 0.9940000176429749\n",
      "Epoch 39 \t | Training Accuracy = 0.9940000176429749\n",
      "Epoch 40 \t | Training Accuracy = 0.9940000176429749\n",
      "Epoch 41 \t | Training Accuracy = 0.9940000176429749\n",
      "Epoch 42 \t | Training Accuracy = 0.9929999709129333\n",
      "Epoch 43 \t | Training Accuracy = 0.9929999709129333\n",
      "Epoch 44 \t | Training Accuracy = 0.9940000176429749\n",
      "Epoch 45 \t | Training Accuracy = 0.9940000176429749\n",
      "Epoch 46 \t | Training Accuracy = 0.9940000176429749\n",
      "Epoch 47 \t | Training Accuracy = 0.9940000176429749\n",
      "Epoch 48 \t | Training Accuracy = 0.9940000176429749\n",
      "Epoch 49 \t | Training Accuracy = 0.9940000176429749\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(number_of_epochs):\n",
    "    # Training Datset\n",
    "     for i in range(number_iterations):\n",
    "            batch_x ,batch_y = next_batch(batch_size=size_of_batch, dataset = x_train, labels = y_train)\n",
    "            \n",
    "            feed_dictionary = {X: batch_x, Y: batch_y}\n",
    "            \n",
    "            session.run(train_step, feed_dict = feed_dictionary)\n",
    "            \n",
    "     s, batch_accuracy = session.run(fetches= [merged_summary, accuracy], feed_dict= feed_dictionary)\n",
    "     train_writer.add_summary(s,epoch)\n",
    "        \n",
    "     print(f'Epoch {epoch} \\t | Training Accuracy = {batch_accuracy}')\n",
    "    \n",
    "    # Validation Datset\n",
    "     summary = session.run(fetches=merged_summary, feed_dict={X:x_validation, Y:y_validation})\n",
    "     validation_writer.add_summary(summary, epoch)\n",
    "    \n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b0dc60",
   "metadata": {},
   "source": [
    "## Reset for the next Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "69cf27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer.close()\n",
    "validation_writer.close()\n",
    "session.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517dfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90986e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5420f501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc97dac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db999db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03ae262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3698def7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc6a212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766179ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf9af60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
